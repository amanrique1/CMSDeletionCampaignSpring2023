{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rucio.client import Client\n",
    "from Oracle import Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9924ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rucio = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc2619",
   "metadata": {},
   "source": [
    "# Deletion File Load\n",
    "Previously defined datasets to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b81b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dropping_sorted_spring2023.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab444f95",
   "metadata": {},
   "source": [
    "# Query Construction\n",
    "The idea is by code to add all the datasets to find. They will be formatted in the delete_datasets section and will be kept by the with. These will be used to get the file names (child names) by joining them with the CONTENTS table, this table is at block level, so it requires a substring and a group by section to have the desired granularity. After that, it is joined with LOCKS and RSES to get all the rules protecting the files and the rse name to make it more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353326b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_op = \"\"\"\n",
    "WITH delete_datasets AS (\n",
    "{}\n",
    "),\n",
    "delete_child_names AS (\n",
    "    SELECT CHILD_NAME, DATASET   \n",
    "    FROM cms_rucio_prod.CONTENTS c\n",
    "    INNER JOIN delete_datasets ON Substr(name, 1, Instr(name, '#') - 1) = delete_datasets.DATASET\n",
    "    GROUP BY CHILD_NAME, DATASET \n",
    ")\n",
    "SELECT *\n",
    "FROM (\n",
    "SELECT dataset, rule_id, rse, RSE_TYPE, count(DISTINCT name) OVER(PARTITION BY dataset, rse) AS FILES_NUMBER, sum(bytes) OVER(PARTITION BY dataset, rule_id, rse) AS FILES_SIZE\n",
    "FROM (\n",
    "SELECT dataset, name, rule_id, rse, RSE_TYPE, bytes\n",
    "FROM delete_child_names d\n",
    "INNER JOIN cms_rucio_prod.LOCKS l ON d.CHILD_NAME = l.NAME\n",
    "INNER JOIN cms_rucio_prod.RSES r ON r.ID = l.RSE_ID)\n",
    ")\n",
    "GROUP BY dataset, rule_id, rse, RSE_TYPE, FILES_NUMBER,FILES_SIZE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the text needed from each dataset to be part of the WITH statement\n",
    "# DUAL is just used as joker it doesn't have any responsability, could be any table\n",
    "def get_dataset_query(dataset_name):\n",
    "    return f\"SELECT '{dataset_name}' AS DATASET FROM DUAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be719e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the query string for each dataset\n",
    "vectorized_get_dataset_query = np.vectorize(get_dataset_query)\n",
    "# Concat all the statements with an UNION ALL\n",
    "dataset = ' UNION ALL '.join(list(vectorized_get_dataset_query(df['dataset'].unique())))\n",
    "# Add the statement to the SQL Query\n",
    "query_op = query_op.format(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab5ef6",
   "metadata": {},
   "source": [
    "# Execute Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = os.environ.get('ORACLE_HOST')\n",
    "port = os.environ.get('ORACLE_PORT')\n",
    "service = os.environ.get('ORACLE_SERVICE_NAME')\n",
    "username = os.environ.get('ORACLE_USERNAME')\n",
    "password = os.environ.get('ORACLE_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbManager = Oracle(host,port,service,username,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rse = dbManager.query(query_op)\n",
    "df_rse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7e0b58",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02696cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rse.to_csv('deletion_rules_spring2023.csv',index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
